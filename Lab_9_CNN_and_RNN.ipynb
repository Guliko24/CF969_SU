{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Guliko24/CF969_SU/blob/main/Lab_9_CNN_and_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROB4hTgAZ4FR"
      },
      "source": [
        "# CF969 - Big Data for Computational Finance\n",
        "## Lab 9: Convolutional and Recurrent Neural Networks\n",
        "\n",
        "In this lab we will see how to use two of the main network architectures in deep learning:\n",
        "* Convolutional Networks,\n",
        "* Recurrent Neural Networks.\n",
        "\n",
        "When going through these notes, please experiment with the pieces of code, take your time with them, and look up the meaning of the various statements in the online TensorFlow documentation whenever you do not fully understand what is happening.\n",
        "\n",
        "## Convolutional Networks\n",
        "\n",
        "LeNet-5 is an example of a simple convolutional network for handwritten character recognition. Its architecture is summarised in the following picture.\n",
        "\n",
        "![title](imagesCNN/lenet5.png)\n",
        "\n",
        "There are 7 layers in LeNet-5: The first 6 are layers of convolution layers interchanged with pooling layers. The final layer is a fully connected layer with a rather unusual activation function where the weights and biases were manually set. Another peculiarity is that the kernels of the second convolutional layer (C3) do not always use all of the features computed in the previous layer (C2): you can see in the image above that the kernel count in C3 is 16 while the feature count in S2 is 6; not a divisor of 16.\n",
        "\n",
        "This well-known convolutional network achieves an accuracy of over 99% on the MNIST dataset.\n",
        "\n",
        "For more information on this network, see the original publication:\n",
        "* Y. LeCunn, L. Bottou, Y. Bengio, P. Haffner. _\"Gradient Based Learning Applied to Document Recognition.\"_ Proceedings of the IEEE. 1998. http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf\n",
        "\n",
        "As a reminder, the convolution operation is summarised in the following picture. Also see the last set of slides of the module and Chapter 6 of Nielsen's book.\n",
        "\n",
        "![title](imagesCNN/convolution.png)\n",
        "\n",
        "A convolution operation takes an input matrix (typically representing an image) and computes for all entries at a certain interval distance in the matrix a weighted sum (plus possibly a bias) of the entries around it (including itself). The result is a smaller matrix containing all these weighted sums as entries. The interval distance is called the stride length. In the above picture the weights correspond to performing an embossing operation on the image. The weights and bias applied to each pixel are the same. Usually, multiple such convolution operations are applied in parallel in a single convolutional layer, this produces multiple separate matrices. For example, in the first layer of LeNet-5 you can see that six convolution operations are applied.\n",
        "\n",
        "A pooling operation shrinks such a matrix further by partitioning it in blocks, and summarising each of the blocks in some way by a single value. A typical choice here is the max-function, where simply the max value of such a block is output. The result of a pooling operation is a significantly smaller matrix where each entry represents the pooling result of each separate block.\n",
        "\n",
        "Using convolutions and pooling instead of simply applying a fully connected layer on our inputs has some advantages:\n",
        "* There are relatively little weights to train, as the weights are shared for each pixel.\n",
        "* These operations assume that the input is in the form of a matrix, which can be a natural choice of input depending on the data at hand. In the case of input in the form of an image, this certainly is true, and the convolution operation implicitly takes into account the spatial structure of the input.\n",
        "* Sometimes certain sparseness restrictions are also imposed on the weights of a convolution layer. In the convolution operation depicted above, almost all weights are zero. Imposing this explicitly can further reduce the size of the parameter space, and will significantly speed up training.\n",
        "\n",
        "In TensorFlow, as you may have guessed, the convolution operation is built-in. We can apply it as follows, where we assume that we have 28 by 28 input pictures, as in the  MNIST dataset. (Do not run this code, it will not work by itself of course. Just inspect this code for now.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eSK42ivxZ4FV"
      },
      "outputs": [],
      "source": [
        "x = tf.nn.conv2d(x, W, strides=[1, stride_length, stride_length,1], padding='SAME')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8829ekHZ4FX"
      },
      "source": [
        "Note that here, x is a tensor of rank 4. _stride_length_ is the stride length associated to the convolution operation.\n",
        "\n",
        "What would happen if our input pictures were provided to us in full color, rather than just greyscale? In that case, each pixel would probably be represented on three channels: one for red, one for green, one for blue. This could be represented as three separate 28 by 28 matrices, or even better: a rank 3 tensor, where there are 3 entries along the third axis of the tensor. The convolution operation would also become a 3-dimensional one, where for a single pixel a sum of weights is taken over all surrounding pixels, where each surrounding pixel has 3 values. For example, if we would assume 28 by 28 input images, with colored pixels encoded over three channels, and we would apply five convolution operations in parallel on it, then the operation can be depicted as follows.\n",
        "\n",
        "![title](imagesCNN/colorconvolution.png)\n",
        "\n",
        "The above code would be rewritten into the following. Again, do not run this code, but do inspect and compare with the above variant of the code, so as to understand what is the role of the various values in the vectors that we specify."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hw_juF_rZ4FX"
      },
      "source": [
        "As I explained in the lecture, convolution operations are usually interchanged with pooling operations to reduce the size of the data output by the pooling layer. Pooling is also called _subsampling_ or _downsampling_. The following picture displays how 2 times 2 max-pooling works on a 4 times 4 matrix. The output is half the size of the input.\n",
        "\n",
        "![title](imagesCNN/pooling.png)\n",
        "\n",
        "In TensorFlow, max-pooling is again built-in. Max-pooling of 2 by 2 can be called as follows. Again, this line of code is not intended to be run. We will combine all of the code later on into a piece of code that actually works."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kb9kQaKEZ4FY"
      },
      "outputs": [],
      "source": [
        "tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhhSZjh5Z4FY"
      },
      "source": [
        "When we train convolutional networks, we see that often the final result will be a network in which the convolutional weights represent clear geometric shapes that the network is trying to detect. Below is a visualisation of the various convolution weights that result from training a famous neural network for ImageNet, coming from the following paper:\n",
        "\n",
        "* A. Krizhevsky, Ilya Sutskever, and G. E. Hinton. _ImageNet classification with deep convolutional neural networks_. Advances in neural information processing systems. 2012. https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf\n",
        "\n",
        "![title](imagesCNN/imagenetconvolution.png)\n",
        "\n",
        "You can see here that some of the convolution operations are testing the input for patterns that resemble edges along various orientations. This is a great example of a way in which modern deep learning technology derives its success from the ability to decompose the task into subtasks; and identifying the correct subtasks through a learning algorithm. In this case such subtasks consist in the identification of edges with a variety of orientations in local regions of the picture.\n",
        "\n",
        "This particular convolutional network by Krizhevsky et al. was trained on 1.2 million high-resolution images, in the ImageNet LSVRC-2010 contest. The task for the network is to identify over thousand possible types of objects in the input picture, i.e., to classify the dataset into 1000 different classes. The accuracy is measured by the likelihood ranking that the network outputs. On the test data, they achieved top-1 and top-5 error rates of 37.5% and 17.0%.\n",
        "Training from scratch took \"Ô¨Åve to six days on two NVIDIA GTX 580 3GB GPUs.\"\n",
        "\n",
        "**Exercise:** We now combine the TensorFlow functions implemented above into a single convolutional network for handwritten digit classification on the MNIST dataset. The code implements a couple of other techniques as well that we have learned throughout our journey: A stochastic version of gradient descent, and dropout are included as well. Your task is to run the code and to work out the answers to the following questions:\n",
        "\n",
        "* How many convolutional layers are there?\n",
        "* How many pooling layers are used?\n",
        "* How many fully connected layers are there?\n",
        "* Are there any further layers?\n",
        "* How many convolution operations per layer are applied?\n",
        "* What type of activation functions are used?\n",
        "* How many weights and biases are trained in each of the convolution layers?\n",
        "\n",
        "Running the code probably gives you an accuracy of over 96%. Note that this is a substantial piece of code and it might take you quite a bit of time to understand it. Please tell me in case you would like to discuss some of this code or have something clarified."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SxrJXEDqZ4FZ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model, layers\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zj1ATK99Z4FZ"
      },
      "outputs": [],
      "source": [
        "# Network Parameters\n",
        "num_classes = 10 # MNIST total classes (0-9 digits)\n",
        "dropout = 0.75 # Dropout, probability to keep units\n",
        "\n",
        "# Training parameters\n",
        "learning_rate = 0.001\n",
        "training_iters = 20000\n",
        "batch_size = 128\n",
        "display_step = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HukvCh4yZ4Fa"
      },
      "source": [
        "In previous lab scripts, we used to train based on the entire input. This is, in principle, time-consuming, so it is advised to train based on large chunks of the input. The next code snippet allows us to break the data into batches of given size.  Recall that, by doing so, we lose some of the nice theoretical learning-related properties. Also, we make sure to randomize when breaking into batches, so as to avoid limiting ourselves to a batch that is not statistically independent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kLAs41ZlZ4Fb"
      },
      "outputs": [],
      "source": [
        "def next_batch(num, data, labels):\n",
        "\tidx = np.arange(0 , len(data))\n",
        "\tnp.random.shuffle(idx)\n",
        "\tidx = idx[:num] # pull off first num items only\n",
        "\tdata_shuffle = data[idx] # pull off only selected rows\n",
        "\tlabels_shuffle = labels[idx] # pull off only selected rows\n",
        "\treturn data_shuffle, labels_shuffle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amUmH89zZ4Fb"
      },
      "source": [
        "Time to load and manipulate the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HdArF-pmZ4Fb"
      },
      "outputs": [],
      "source": [
        "# Load dataset\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Convert to float32\n",
        "train_images, test_images = np.array(train_images, np.float32), np.array(test_images, np.float32)\n",
        "\n",
        "# Normalize images value from [0, 255] to [0, 1]\n",
        "train_images, test_images = train_images / 255., test_images / 255."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmnybrlkZ4Fc"
      },
      "source": [
        "We now define the key tools for the neural network. The main two operations, convolution and max-pooling, are defined as follows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TjF1n37oZ4Fc"
      },
      "outputs": [],
      "source": [
        "# Create some wrappers for simplicity\n",
        "def conv2d(x, W, b, strides=1):\n",
        "    # Conv2D wrapper, with bias and relu activation\n",
        "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
        "    x = tf.nn.bias_add(x, b)\n",
        "    return tf.nn.relu(x)\n",
        "\n",
        "def maxpool2d(x, k=2):\n",
        "    # MaxPool2D wrapper\n",
        "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding='SAME')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhUlhpttZ4Fc"
      },
      "source": [
        "We are now ready to create the CNN."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cshWC0jRZ4Fc"
      },
      "outputs": [],
      "source": [
        "# Create model (CNN network)\n",
        "def conv_net(x):\n",
        "    # Reshape input picture\n",
        "    # Input shape: [-1, 28, 28, 1]. A batch of 28x28x1 (grayscale) images.\n",
        "    x = tf.reshape(x, shape=[-1, 28, 28, 1])\n",
        "\n",
        "    # Convolution Layer. Output shape: [-1, 28, 28, 32].\n",
        "    conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n",
        "\n",
        "    # Max Pooling (down-sampling). Output shape: [-1, 14, 14, 32].\n",
        "    conv1 = maxpool2d(conv1, k=2)\n",
        "\n",
        "    # Convolution Layer. Output shape: [-1, 14, 14, 64].\n",
        "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
        "\n",
        "    # Max Pooling (down-sampling)\n",
        "    conv2 = maxpool2d(conv2, k=2)\n",
        "\n",
        "    # Reshape conv2 output to fit fully connected layer input, Output shape: [-1, 7*7*64].\n",
        "    fc1 = tf.reshape(conv2, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
        "\n",
        "    # Fully connected layer, Output shape: [-1, 1024].\n",
        "\n",
        "    fc1 = tf.nn.relu(tf.matmul(fc1, weights['wd1']) + biases['bd1'])\n",
        "    # Apply Dropout\n",
        "    fc1 = tf.nn.dropout(fc1, dropout)\n",
        "\n",
        "    # Output, class prediction\n",
        "    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
        "    return tf.nn.softmax(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G4tN1MfQZ4Fd"
      },
      "outputs": [],
      "source": [
        "# Store layers weight & bias\n",
        "\n",
        "# A random value generator to initialize weights.\n",
        "random_normal = tf.initializers.RandomNormal()\n",
        "\n",
        "weights = {\n",
        "    # Conv Layer 1: 5x5 conv, 1 input, 32 filters (MNIST has 1 color channel only).\n",
        "    'wc1': tf.Variable(random_normal([5, 5, 1, 32])),\n",
        "    # Conv Layer 2: 5x5 conv, 32 inputs, 64 filters.\n",
        "    'wc2': tf.Variable(random_normal([5, 5, 32, 64])),\n",
        "    # FC Layer 1: 7*7*64 inputs, 1024 units.\n",
        "    'wd1': tf.Variable(random_normal([7*7*64, 1024])),\n",
        "    # FC Out Layer: 1024 inputs, 10 units (total number of classes)\n",
        "    'out': tf.Variable(random_normal([1024, num_classes]))\n",
        "}\n",
        "\n",
        "biases = {\n",
        "    'bc1': tf.Variable(tf.zeros([32])),\n",
        "    'bc2': tf.Variable(tf.zeros([64])),\n",
        "    'bd1': tf.Variable(tf.zeros([1024])),\n",
        "    'out': tf.Variable(tf.zeros([num_classes]))\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5EM43BUJZ4Fd"
      },
      "outputs": [],
      "source": [
        "# Define loss and optimizer\n",
        "# Cross-Entropy loss function\n",
        "def cross_entropy(y_pred, y_true):\n",
        "    # Encode label to a one hot vector.\n",
        "    y_true = tf.one_hot(y_true, depth=num_classes)\n",
        "    # Clip prediction values to avoid log(0) error.\n",
        "    y_pred = tf.clip_by_value(y_pred, 1e-9, 1.)\n",
        "    # Compute cross-entropy.\n",
        "    return tf.reduce_mean(-tf.reduce_sum(y_true * tf.math.log(y_pred)))\n",
        "\n",
        "# Accuracy metric\n",
        "def accuracy(y_pred, y_true):\n",
        "    # Predicted class is the index of highest score in prediction vector (i.e. argmax).\n",
        "    correct_prediction = tf.equal(tf.argmax(y_pred, 1), tf.cast(y_true, tf.int64))\n",
        "    return tf.reduce_mean(tf.cast(correct_prediction, tf.float32), axis=-1)\n",
        "\n",
        "# Stochastic Gradient Descent optimizer\n",
        "optimizer = tf.optimizers.SGD(learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-vFu1UQTZ4Fd"
      },
      "outputs": [],
      "source": [
        "# Optimization process.\n",
        "def run_optimization(x, y):\n",
        "    # Wrap computation inside a GradientTape for automatic differentiation.\n",
        "    with tf.GradientTape() as g:\n",
        "        pred = conv_net(x)\n",
        "        loss = cross_entropy(pred, y)\n",
        "\n",
        "    # Variables to update, i.e. trainable variables.\n",
        "    trainable_variables = list(weights.values()) + list(biases.values())\n",
        "\n",
        "    # Compute gradients.\n",
        "    gradients = g.gradient(loss, trainable_variables)\n",
        "\n",
        "    # Update W and b following gradients.\n",
        "    optimizer.apply_gradients(zip(gradients, trainable_variables))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YV76JiSZ4Fe"
      },
      "source": [
        "All done! Time to train."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yfwoIpZ9Z4Fe"
      },
      "outputs": [],
      "source": [
        "# Run training\n",
        "step = 1\n",
        "while step * batch_size < training_iters:\n",
        "    batch_x, batch_targets = next_batch(batch_size, train_images, train_labels)\n",
        "\n",
        "    # Run the optimization to update W and b values.\n",
        "    run_optimization(batch_x, batch_targets)\n",
        "    step += 1\n",
        "    if step % display_step == 0:\n",
        "        pred = conv_net(batch_x)\n",
        "        loss = cross_entropy(pred, batch_targets)\n",
        "        acc = accuracy(pred, batch_targets)\n",
        "        print(\"step: %i, loss: %f, accuracy: %f\" % (step, loss, acc))\n",
        "print(\"Training finished!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PMzk37siZ4Fe"
      },
      "outputs": [],
      "source": [
        "# Test model on validation set.\n",
        "pred = conv_net(test_images)\n",
        "print(\"Test Accuracy: %f\" % accuracy(pred, test_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tB7k9lLfZ4Fe"
      },
      "outputs": [],
      "source": [
        "# Visualize predictions.\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fBWTXCfrZ4Fe"
      },
      "outputs": [],
      "source": [
        "# Predict 5 images from validation set.\n",
        "n_images = 5\n",
        "test_set = test_images[:n_images]\n",
        "predictions = conv_net(test_set)\n",
        "\n",
        "# Display image and model prediction.\n",
        "for i in range(n_images):\n",
        "    plt.imshow(np.reshape(test_images[i], [28, 28]), cmap='gray')\n",
        "    plt.show()\n",
        "    print(\"Model prediction: %i\" % np.argmax(predictions.numpy()[i]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cl5Cs9sWZ4Fe"
      },
      "source": [
        "**Exercise:** Modify and re-run the code so that there is one instead of two convolutional layers (and therefore one instead of two pooling layers), a higher stride length, a lower keep probability for dropout, different activation functions, and a higher number of features in the first convolutional layer.\n",
        "\n",
        "For additional reading and practice with convolutional networks, please also take a look at https://cs231n.github.io/convolutional-networks/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tC4rU8DIZ4Fe"
      },
      "source": [
        "## Simplifying the CNN\n",
        "The code above is rather low-level. This has the benefit that it provides more power and control to the programmer. On the other hand, it might be easier to make a mistake or fail to implement it properly.\n",
        "\n",
        "The following two code snippets offer simplifications. The first one replaces setting weights and biases, defining wrappers, and defining the model. The second one replaces the cross-entropy error function.\n",
        "\n",
        "How can you combine the previous code  with the snippets below? Please try the combination in a new notebook. Apart from the following couple of snippets, _trainable_variables_ in _run_optimization_ should now be set as _trainable_variables_ = _conv_net.trainable_variables_\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o2deThNwZ4Fe"
      },
      "outputs": [],
      "source": [
        "# Create TF Model\n",
        "class ConvNet(Model):\n",
        "    # Set layers\n",
        "    def __init__(self):\n",
        "        super(ConvNet, self).__init__()\n",
        "        # Convolution Layer with 32 filters and a kernel size of 5\n",
        "        self.conv1 = layers.Conv2D(32, kernel_size=5, activation=tf.nn.relu)\n",
        "        # Max Pooling (down-sampling) with kernel size of 2 and strides of 2\n",
        "        self.maxpool1 = layers.MaxPool2D(2, strides=2)\n",
        "\n",
        "        # Convolution Layer with 64 filters and a kernel size of 3\n",
        "        self.conv2 = layers.Conv2D(64, kernel_size=3, activation=tf.nn.relu)\n",
        "        # Max Pooling (down-sampling) with kernel size of 2 and strides of 2\n",
        "        self.maxpool2 = layers.MaxPool2D(2, strides=2)\n",
        "\n",
        "        # Flatten the data to a 1-D vector for the fully connected layer\n",
        "        self.flatten = layers.Flatten()\n",
        "\n",
        "        # Fully connected layer\n",
        "        self.fc1 = layers.Dense(1024)\n",
        "        # Apply Dropout (if is_training is False, dropout is not applied)\n",
        "        self.dropout = layers.Dropout(rate=0.5)\n",
        "\n",
        "        # Output layer, class prediction\n",
        "        self.out = layers.Dense(num_classes)\n",
        "\n",
        "    # Set forward pass\n",
        "    def call(self, x, is_training=False):\n",
        "        x = tf.reshape(x, [-1, 28, 28, 1])\n",
        "        x = self.conv1(x)\n",
        "        x = self.maxpool1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.maxpool2(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc1(x)\n",
        "        x = self.dropout(x, training=is_training)\n",
        "        x = self.out(x)\n",
        "        if not is_training:\n",
        "            # tf cross entropy expect logits without softmax, so only\n",
        "            # apply softmax when not training\n",
        "            x = tf.nn.softmax(x)\n",
        "        return x\n",
        "\n",
        "# Build neural network model\n",
        "conv_net = ConvNet()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V_tUC1SUZ4Ff"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Cross-Entropy Loss\n",
        "# Note that this will apply 'softmax' to the logits\n",
        "def cross_entropy_loss(x, y):\n",
        "    # Convert labels to int 64 for tf cross-entropy function\n",
        "    y = tf.cast(y, tf.int64)\n",
        "    # Apply softmax to logits and compute cross-entropy\n",
        "    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=x)\n",
        "    # Average loss across the batch\n",
        "    return tf.reduce_mean(loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCgN9X5-Z4Fg"
      },
      "source": [
        "## Recurrent Neural Networks\n",
        "\n",
        "Now, I would like to cover an example of a recurrent neural network with LSTM units. RNNs involve a notion of time: the input is provided over a sequence of time steps. In the case of this network, for each training example the input is provided over a period of 28 time steps, where at each step the network receives a row of 28 pixels of the input.\n",
        "\n",
        "Please inspect the code, and consult the TensorFlow reference to obtain information and insight on the various functions that are used here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S0hz_EoAZ4Fg"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model, layers\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j6wWNufHZ4Fg"
      },
      "outputs": [],
      "source": [
        "# Network Parameters\n",
        "num_classes = 10 # MNIST total classes (0-9 digits)\n",
        "dropout = 0.75 # Dropout, probability to keep units\n",
        "num_input = 28 # number of sequences\n",
        "timesteps = 28 # timesteps\n",
        "num_units = 32 # number of neurons for the LSTM layer\n",
        "\n",
        "# Training parameters\n",
        "learning_rate = 0.001\n",
        "training_iters = 20000\n",
        "batch_size = 128\n",
        "display_step = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8sREduUZZ4Fg"
      },
      "outputs": [],
      "source": [
        "def next_batch(num, data, labels):\n",
        "\tidx = np.arange(0 , len(data))\n",
        "\tnp.random.shuffle(idx)\n",
        "\tidx = idx[:num] # pull off first num items only\n",
        "\tdata_shuffle = data[idx] # pull off only selected rows\n",
        "\tlabels_shuffle = labels[idx] # pull off only selected rows\n",
        "\treturn data_shuffle, labels_shuffle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uVOO8mIoZ4Fg"
      },
      "outputs": [],
      "source": [
        "# Load dataset\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Convert to float32\n",
        "train_images, test_images = np.array(train_images, np.float32), np.array(test_images, np.float32)\n",
        "\n",
        "# Normalize images value from [0, 255] to [0, 1]\n",
        "train_images, test_images = train_images / 255., test_images / 255."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xHgr3mO5Z4Fh"
      },
      "outputs": [],
      "source": [
        "# Create LSTM Model\n",
        "class LSTM(Model):\n",
        "    # Set layers.\n",
        "    def __init__(self):\n",
        "        super(LSTM, self).__init__()\n",
        "        # RNN (LSTM) hidden layer\n",
        "        self.lstm_layer = layers.LSTM(units=num_units)\n",
        "        self.out = layers.Dense(num_classes)\n",
        "\n",
        "    # Set forward pass\n",
        "    def call(self, x, is_training=False):\n",
        "        # LSTM layer\n",
        "        x = self.lstm_layer(x)\n",
        "        # Output layer (num_classes)\n",
        "        x = self.out(x)\n",
        "        if not is_training:\n",
        "            # tf cross entropy expect logits without softmax, so only\n",
        "            # apply softmax when not training\n",
        "            x = tf.nn.softmax(x)\n",
        "        return x\n",
        "\n",
        "# Build LSTM model\n",
        "lstm_net = LSTM()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "31Zl_6KPZ4Fh"
      },
      "outputs": [],
      "source": [
        "# Cross-Entropy Loss\n",
        "# Note that this will apply 'softmax' to the logits\n",
        "def cross_entropy_loss(x, y):\n",
        "    # Convert labels to int 64 for tf cross-entropy function\n",
        "    y = tf.cast(y, tf.int64)\n",
        "    # Apply softmax to logits and compute cross-entropy\n",
        "    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=x)\n",
        "    # Average loss across the batch\n",
        "    return tf.reduce_mean(loss)\n",
        "\n",
        "# Accuracy metric\n",
        "def accuracy(y_pred, y_true):\n",
        "    # Predicted class is the index of highest score in prediction vector (i.e. argmax)\n",
        "    correct_prediction = tf.equal(tf.argmax(y_pred, 1), tf.cast(y_true, tf.int64))\n",
        "    return tf.reduce_mean(tf.cast(correct_prediction, tf.float32), axis=-1)\n",
        "\n",
        "# Adam optimizer\n",
        "optimizer = tf.optimizers.Adam(learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JVFQ6yxwZ4Fh"
      },
      "outputs": [],
      "source": [
        "# Optimization process\n",
        "def run_optimization(x, y):\n",
        "    # Wrap computation inside a GradientTape for automatic differentiation\n",
        "    with tf.GradientTape() as g:\n",
        "        # Forward pass.\n",
        "        pred = lstm_net(x, is_training=True)\n",
        "        # Compute loss.\n",
        "        loss = cross_entropy_loss(pred, y)\n",
        "\n",
        "    # Variables to update, i.e. trainable variables\n",
        "    trainable_variables = lstm_net.trainable_variables\n",
        "\n",
        "    # Compute gradients\n",
        "    gradients = g.gradient(loss, trainable_variables)\n",
        "\n",
        "    # Update weights following gradients\n",
        "    optimizer.apply_gradients(zip(gradients, trainable_variables))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rrx6DgYfZ4Fh"
      },
      "outputs": [],
      "source": [
        "# Run training\n",
        "step = 1\n",
        "while step * batch_size < training_iters:\n",
        "    batch_x, batch_targets = next_batch(batch_size, train_images, train_labels)\n",
        "\n",
        "    # Run the optimization to update W and b values.\n",
        "    run_optimization(batch_x, batch_targets)\n",
        "    step += 1\n",
        "    if step % display_step == 0:\n",
        "        pred = lstm_net(batch_x, is_training=True)\n",
        "        loss = cross_entropy_loss(pred, batch_targets)\n",
        "        acc = accuracy(pred, batch_targets)\n",
        "        print(\"step: %i, loss: %f, accuracy: %f\" % (step, loss, acc))\n",
        "print(\"Training finished!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbem8CTDZ4Fh"
      },
      "source": [
        "Clearly, using RNNs for solving static image classification problems which do not naturally involve any notion of time, might not seem like the most natural choice. Nonetheless, please run the code and take a look at the resulting test accuracy.\n",
        "\n",
        "For more practice with LSTMs, see the following three resources.\n",
        "* Tutorial on word2vec, which can be used with RNNs to solve language tasks: https://www.tensorflow.org/tutorials/representation/word2vec\n",
        "* Wikipedia page on LSTMs: https://en.wikipedia.org/wiki/Long_short-term_memory\n",
        "* _The Unreasonable Effectiveness of Recurrent Neural Networks_ by Andrej Karpathy: http://karpathy.github.io/2015/05/21/rnn-effectiveness/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7P7f00lqZ4Fh"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}