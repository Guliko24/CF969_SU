{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPqxBPlH2j5W0ryeXSB1Lq8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Guliko24/CF969_SU/blob/main/Queez_8_codingQuestion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In a previous lecture we discussed an XOR example and a neural network that would \"learn\" how to mimic it. See also Part 1 of the notebook \"Lab 7b - Building a Neural Network\" where a very similar setting is discussed.\n",
        "\n",
        "In this task, you are asked to consider the NAND function: this takes in input two variables taking values of either 0 or 1 and returns in output 1 if at most one input is 1 and returns 0 otherwise. In the neural network, there are two input nodes (x_1, and x_2), one hidden layer with four nodes, and a single output node. The nodes in the hidden layers have ReLU activation functions, while the output node has a sigmoid activation function. Assume that the initial weights and biases are randomly generated according to a normal distribution with standard deviation 0.2.\n",
        "\n",
        "Write code \"by hand\" that implements this design, trains the network using Stochastic Gradient Descent, and outputs the weights and biases.\n",
        "\n",
        "This means that you cannot use the Tensorflow and keras built-in functions to construct the layers, but you must follow the approach in Part 1 of notebook Lab 7b."
      ],
      "metadata": {
        "id": "17uA5vTUwp5e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "JOx8Wr-S5OGC"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Lets define input and output data for NAND function\n",
        "x=tf.constant([[0,0],[0,1],[1,0],[1,1]], tf.float32) # our input vector\n",
        "y_true = tf.constant([[1], [1], [1], [0]], tf.float32)  # Expected output\n",
        "\n",
        "#Initialize weights and biases\n",
        "w1 = tf.Variable(tf.random.truncated_normal([2,4], stddev=0.2))\n",
        "b1 = tf.Variable(tf.random.truncated_normal([1,4], stddev=0.2))\n",
        "w2 = tf.Variable(tf.random.truncated_normal([4,1], stddev=0.2))\n",
        "b2 = tf.Variable(tf.random.truncated_normal([1,1], stddev=0.2))\n",
        "\n",
        "#Define the forward pass\n",
        "def forward_pass(x):\n",
        "  h=tf.nn.relu(tf.matmul(x,w1) + b1)\n",
        "  y_pred=tf.sigmoid(tf.matmul(h,w2)+b2)\n",
        "  return y_pred\n",
        "\n",
        "#define loss function\n",
        "def loss():\n",
        "    y_pred = forward_pass(x)\n",
        "    return tf.reduce_sum(tf.square(y_pred - y_true))\n",
        "\n",
        "#define optimizer\n",
        "optimizer = tf.optimizers.SGD(0.5)\n",
        "\n",
        "for i in range(20):\n",
        "    optimizer.minimize(loss,[w1,b1,w2,b2])\n",
        "\n",
        "#trainig the neural networks\n",
        "epochs=10000\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    optimizer.minimize(loss, [w1, b1, w2, b2])\n",
        "    if epoch % 1000 == 0:\n",
        "        current_loss = loss().numpy()\n",
        "        print(f'Epoch {epoch}, Loss: {current_loss}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRBTmW4d7FEv",
        "outputId": "8df3bb99-ab6d-48b6-9499-ea26422d4184"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.7352818250656128\n",
            "Epoch 1000, Loss: 0.0009663007222115993\n",
            "Epoch 2000, Loss: 0.00044198730029165745\n",
            "Epoch 3000, Loss: 0.00028329354245215654\n",
            "Epoch 4000, Loss: 0.00020703705376945436\n",
            "Epoch 5000, Loss: 0.00016299021081067622\n",
            "Epoch 6000, Loss: 0.00013404223136603832\n",
            "Epoch 7000, Loss: 0.00011376720067346469\n",
            "Epoch 8000, Loss: 9.867229528026655e-05\n",
            "Epoch 9000, Loss: 8.713892020750791e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Output the final weights and biases\n",
        "print(\"Final W1:\", w1.numpy())\n",
        "print(\"Final b1:\", b1.numpy())\n",
        "print(\"Final W2:\", w2.numpy())\n",
        "print(\"Final b2:\", b2.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvDIG4JFvH0l",
        "outputId": "552a4391-d26c-4dd4-ef53-f2990eaf5735"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final W1: [[ 0.615292   -2.3201916  -0.15140043 -0.25011688]\n",
            " [-1.6500714  -1.6241784  -0.07371277 -0.2931311 ]]\n",
            "Final b1: [[ 1.0345917   3.944045   -0.00514548 -0.15050083]]\n",
            "Final W2: [[ 1.9920901 ]\n",
            " [ 4.6445713 ]\n",
            " [-0.09165938]\n",
            " [-0.20477255]]\n",
            "Final b2: [[-4.808344]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "TS6J9tU44-Ft"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Yt8SpYBp6NF_"
      },
      "execution_count": 26,
      "outputs": []
    }
  ]
}